{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9vdx3fcvtl0"
      },
      "source": [
        "\n",
        "\n",
        " <h1>  <center> <b> Speech Systems (EE6307) </b> </center>\n",
        "\n",
        "<dt> <h4> <b> Programming Assignment 06 : Connectionist Temporal Classification (CTC) loss & ASR Decoders </b> </h4> </dt>\n",
        "\n",
        "\n",
        "<dt> <h4>  $\\underline{\\textbf{Objective}}$:\n",
        "\n",
        "Welcome to the sixth programming assignment (PA) in the Speech Systems (EE6307) course. The goal of this PA is to develop an algorithm that recognizes text from a speech signal, i.e., Automatic Speech Recognition (ASR). The end-to-end ASR system processes a speech signal as input and learns to predict the corresponding textual information without relying on explicit alignments. Typically, the end-to-end ASR systems are trained using the Connectionist Temporal Classification (CTC) loss. Once the network is trained, the model takes input as speech signal and outputs the probability matrix over characterFor decoding the final text from the model's output, which is a probability matrix over characters, ASR decoders such as Greedy and Beam Search are used. The perofrmance of ASR system is typically quantified using two popular metrics Character Error Rate (CER) and Word Error Rate (WER). This Colab notebook includes code for data preparation, model architecture, training, and inference. However, we have intentionally left out the code for the CTC loss function and the Greedy and Beam Search decoders. You are expected to implement these components from scratch.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " </h4> </dt>\n",
        "\n",
        "<dt> <h4>  <b> $\\underline{\\textbf{Instructions}}$: </b> Please follow these instructions </h4> </dt>\n",
        "<dd> <h4>  1. Plagiarism is strictly prohibited. </h4> </dd>\n",
        "<dd> <h4>  2. Delayed submissions will be penalized with a scaling factor of 0.5 per day. </h4> </dd>\n",
        "<dd> <h4>  3. Please DO NOT use any machine learning libraries unless and otherwise specified. </h4> </dd>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reXi8STg3pM5"
      },
      "source": [
        "<h4> <b> End-to-End Automatic Speech Recognition : </b>   </h4>\n",
        "\n",
        "\n",
        "[link to LibriSpeech database](https://www.openslr.org/12)\n",
        "\n",
        "\n",
        "\n",
        "<dt> <h4> 1. Dataset </h4> </dt>\n",
        "<dd> <h4> - Training data : The ASR system in this assignment needs to be trained using \"train-clean-100\" partition of the Lirbrispeech corpus. Please go though above link for finer details of the dataset </h4> </dd>\n",
        "<dd> <h4> - Testing data : We request you to evaluate the performance of ASR system on \"test-clean\" partition of the Lirbrispeech corpus.  </h4> </dd>\n",
        "\n",
        "<dt> <h4> 2. Data preprocessing </h4> </dt>\n",
        "<dd> <h4> - Convert the target information ( sentence being spoken ) in textual domain to sequence of numbers, where the number indicates the character position in our predefined character set.    </h4> </dd>\n",
        "<dd> <h4> - Extract log-mel filter bank energies from the speech signal    </h4> </dd>\n",
        "\n",
        "<dt> <h4> 3. Automatic Speech Recognition (ASR) - Architecture </h4> </dt>\n",
        "\n",
        "<img src =\"https://raw.githubusercontent.com/SpeechPublications/SpeechSystems/main/model.png\" >\n",
        "<center> Black Diagram of Automatic Speech Recognition Model </center>\n",
        "\n",
        "<dt> <h4> 4. Training ASR system </h4> </dt>\n",
        "<dd> <h4> -  Issue : The input ( speech signal ) and outputs ( text ) are not time aligned. Aligning the data using Hidden Markov Model (HMM) may not be a suitable option.   </h4> </dd>\n",
        "<dd> <h4> -  The ASR system is trained using the Connectionist Temporal Classificaiton (CTC) loss  </h4> </dd>\n",
        "\n",
        "\n",
        "<dt> <h4> 5. Evaluation Metrics </h4> </dt>\n",
        "<dd> <h4> - Typically the performance of ASR system is quantified in terms of Word Error Rate (WER) or Character Error Rate (CER). The codes to compute the WER and CER will be provided to you, use them to evaluate the performance   </h4> </dd>\n",
        "<dd> <h4> -  CER : Percentage of characters that were incorrectly predicted  by the ASR system      </h4> </dd>\n",
        "\n",
        "\n",
        "<dt> <h4> 6. Evaluate the performance of ASR system </h4> </dt>\n",
        "<dd> <h4> -  Use the trained ASR system and predict the characters and words using the basic GreedyDecoder and Beam search decoder. and evaluate the performance in terms of CER and WER  </h4> </dd>\n",
        "<dd> <h4> -  Evaluate the performance of ASR system in terms of CER and WER  </h4> </dd>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDc1nAPM1ZaF"
      },
      "outputs": [],
      "source": [
        "#All imports\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#CTC loss\n",
        "###############################################################################\n",
        "class CTCLoss(nn.Module):\n",
        "    def __init__(self,blank=28):\n",
        "        super(CTCLoss, self).__init__()\n",
        "        self.blank = blank\n",
        "\n",
        "    def forward(self, output, labels, input_lengths, label_lengths):\n",
        "        #Fill the code to compute CTC loss\n",
        "\n",
        "\n",
        "        return ctc_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tTerfFfbcoxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#Greedy decoder\n",
        "###############################################################################\n",
        "def GreedyDecoder(output, labels, label_lengths, blank_label=28, nbest=3, beam_size=1500, word_score=-0.26, collapse_repeated=True):\n",
        "\t#Fill the code to get decoded text and also target text from integer labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\treturn decodes, targets"
      ],
      "metadata": {
        "id": "WKwrIcyRcsdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################################################################\n",
        "#Beam search decoder\n",
        "###############################################################################\n",
        "def BeamSearchDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
        "\t#Fill the code to get decoded text and also target text from integer labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\treturn decodes, targets"
      ],
      "metadata": {
        "id": "J2ssIGLTc1dC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTtHsDtBojpN"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "#Pre-processing the data\n",
        "###############################################################################\n",
        "class TextTransform:\n",
        "    \"\"\"Maps characters to integers and vice versa\"\"\"\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        for line in char_map_str.strip().split('\\n'):\n",
        "            ch, index = line.split()\n",
        "            self.char_map[ch] = int(index)\n",
        "            self.index_map[int(index)] = ch\n",
        "        self.index_map[1] = ' '\n",
        "\n",
        "    def text_to_int(self, text):\n",
        "        \"\"\" Use a character map and convert text to an integer sequence \"\"\"\n",
        "        int_sequence = []\n",
        "        for c in text:\n",
        "            if c == ' ':\n",
        "                ch = self.char_map['<SPACE>']\n",
        "            else:\n",
        "                ch = self.char_map[c]\n",
        "            int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels):\n",
        "        \"\"\" Use a character map and convert integer labels to an text sequence \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[i])\n",
        "        return ''.join(string).replace('<SPACE>', ' ')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Features(nn.Module):\n",
        "    def __init__(self,sample_rate=16000,n_mels=64,n_fft=512,log_input=True):\n",
        "        super(Features, self).__init__()\n",
        "        self.n_mels = n_mels\n",
        "        self.log_input = log_input\n",
        "        self.n_fft = n_fft\n",
        "        self.sample_rate = sample_rate\n",
        "\n",
        "        self.melspectrogram = torch.nn.Sequential( torchaudio.transforms.MelSpectrogram(sample_rate=16000,n_mels=64,n_fft=512) )\n",
        "\n",
        "    def forward(self,x_input):\n",
        "        x_mfb = self.melspectrogram(x_input) + 1e-6\n",
        "        if self.log_input: x_mfb_log = x_mfb.log()\n",
        "        return x_mfb_log\n",
        "\n",
        "train_audio_transforms = nn.Sequential(\n",
        "    Features(),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "#Not applying frequency and time masking during test time\n",
        "valid_audio_transforms = Features()\n",
        "text_transform = TextTransform()\n",
        "\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcuoBuFObJ2p"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "#Speech Recognition Model\n",
        "###############################################################################\n",
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "\n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "class IterMeter(object):\n",
        "    \"\"\"keeps track of total iterations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6gtrRUfpG3M"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "#Training Script\n",
        "###############################################################################\n",
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
        "    #Set the model in training mode\n",
        "    model.train()\n",
        "\n",
        "    #Get the data length\n",
        "    data_len = len(train_loader.dataset)\n",
        "\n",
        "    #Iterate through the training dataset and train the model\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "\n",
        "        #Get the spectrograms (input data), labels (targets)\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data\n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        #Set the gradients of the parameters to zero's\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #Obtain the predictions\n",
        "        output = model(spectrograms)  # (batch, time, n_class)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "        #Compute the loss\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "\n",
        "        #Backpropagate the loss to get the gradients of the parameters\n",
        "        loss.backward()\n",
        "\n",
        "        #Update the parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        #Update the learning rate scheduler\n",
        "        scheduler.step()\n",
        "        iter_meter.step()\n",
        "\n",
        "        #Print the training metrics at regular interval, let us say once in 100 iterations etc\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHhkpaJQbWsN"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "#Evaluation Metrics\n",
        "###############################################################################\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ks4btS9Ip01C"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "#Testing Script\n",
        "###############################################################################\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer1, test_wer1 = [], []\n",
        "    test_cer2, test_wer2 = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            #Load data and labels\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data\n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            #Get the predictions\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            #Compute the test loss\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            #Decode the text information using GreedyDecoder\n",
        "            decoded_preds1, decoded_targets1 = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            decoded_preds2, decoded_targets2 = BeamSearchDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "\n",
        "            #Compute CER and WER (Greedy decoder)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer1.append(cer(decoded_targets1[j], decoded_preds1[j]))\n",
        "                test_wer1.append(wer(decoded_targets1[j], decoded_preds1[j]))\n",
        "\n",
        "            #Compute CER and WER (Beam search decoder)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer2.append(cer(decoded_targets2[j], decoded_preds2[j]))\n",
        "                test_wer2.append(wer(decoded_targets2[j], decoded_preds2[j]))\n",
        "\n",
        "    #Compute average CER and WER (Greedy decoder)\n",
        "    avg_cer1 = sum(test_cer1)/len(test_cer1)\n",
        "    avg_wer1 = sum(test_wer1)/len(test_wer1)\n",
        "\n",
        "    #Compute average CER and WER (Beam search decoder)\n",
        "    avg_cer2 = sum(test_cer2)/len(test_cer2)\n",
        "    avg_wer2 = sum(test_wer2)/len(test_wer2)\n",
        "\n",
        "    print('Greedy decoder: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer1, avg_wer1))\n",
        "    print('Beam search decoder: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer2, avg_wer2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njhOvVzLqRSM"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "#Main script to train and evaluate the model\n",
        "###############################################################################\n",
        "def main(learning_rate=5e-4, batch_size=20, epochs=10,train_url=\"train-clean-100\", test_url=\"test-clean\"):\n",
        "\n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 64,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    #Download the data using \"torchaudio.datasets.LIBRISPEECH()\" function\n",
        "    train_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=train_url, download=True)\n",
        "    test_dataset = torchaudio.datasets.LIBRISPEECH(\"./data\", url=test_url, download=True)\n",
        "\n",
        "    #Create dataset loaders for training\n",
        "    kwargs = {'num_workers': 10, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    #Create dataset loaders for testing\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    #Create model object\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        ).to(device)\n",
        "\n",
        "    #Print model properties i.e layers, parameters etc\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    #Create optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "\n",
        "    #Define loss function\n",
        "    criterion = CTCLoss(blank=28).to(device)\n",
        "\n",
        "    #Define scheduler\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'],\n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "\n",
        "    #Iterate through the epochs and train and test the model\n",
        "    iter_meter = IterMeter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        #Train the model using train(.) function\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n",
        "\n",
        "        #Evaluate the model using test(.) function\n",
        "        test(model, device, test_loader, criterion, epoch, iter_meter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEuNZ2dQqYow"
      },
      "outputs": [],
      "source": [
        "###############################################################################\n",
        "#EXecute main script\n",
        "###############################################################################\n",
        "learning_rate = 5e-4\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "libri_train_set = \"train-clean-100\"\n",
        "libri_test_set = \"test-clean\"\n",
        "\n",
        "main(learning_rate, batch_size, epochs, libri_train_set, libri_test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h4> <b> Report of the assignment : </b>  \n",
        "Write down your observations\n",
        "<dt> <h4> 1.      </h4> </dt>\n",
        "<dt> <h4> 2.      </h4> </dt>\n",
        "<dt> <h4> 3.      </h4> </dt>\n"
      ],
      "metadata": {
        "id": "9GbIc6QRvnin"
      }
    }
  ]
}